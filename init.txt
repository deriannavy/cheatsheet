
Aws has 2 princing fundamentals, following the pay-as-you-go princing model

Compute
Pay for te compute time

Store
pay for data Stored in the cloud

data transfer out of the cloud
data transfer IN is free

- regions
a region is a clusters of data centers (buscar exlicacion)

como elegir una region
* complience (depende del los tipos de datos, y normatividad del uso de los mismos)
* proximidad a usuarios (reducción de la latencia)
* disponibilidad de servicios, existen servicios que no están disponibles en todas las regiones
* precio los precios varian de region a region

- availability zone (buscar explicacion)
* normalmente cada region tiene diversas zonas de disponibilidad
* each availability zne is one or more discrete data center with redundant power, networking and conectivity
* ther are separeate fro each other so what theyre isolated from disasters
* theyre connected with igh bandwidth ultra-low latency networking

aws poins of presence (edge locations)

iam => identity and access management
root => account

grupos pueden contener usuarios

usuarios o grupos pueden tener permisos

las politicas son listas de permisos que se le pueden asignar a grupos o usuarios

[adjuntar un ejemplo como el siguiente]
politicas
policy structure
version
identity[
   {
      id
      effect
      principal: {
         aws:[]
      }
      action:[
         "getobject",
         "getobject"
      ]
   }
]
----------
rol ¿que es? y casos de uso

----------
ec2 config
cpu
ram

-----
nomenclaturas
m5.2xlarge

m => clase de la intancia
5 =>  generacion
2xlarge => tamaño

---- 
Security groups

---- 
EC2 instance connect



----------
EBS

puedes attach a un ec2 
puedes attach 2 ebs a un ec2
o simplemente no estar ligados a nada

delete on terminated
(elimnina el ebs si esta activado una vez que la instancia se termina)

estos no puedes conectarse a otras az

ebs snapshot acchive permite mover tus snapshot a un archive tier para ahorrar dinero, normalmente recuerren más tiempo para restarurarlos (24 a 72)

cuando los eliminas puedes decidir cuanto tiempo estarán en la papelera de reciclaje


----------
AMI => amazon machine image

EC2 instant store ? drives volumes (me parece son sus nvme)

----------
Elastic file system

puede ser montado en hasta 100 EC2 
solo funciona con linux ec2 y es multi AZ
alta disponibliidad escalable y 2x mas caro, se paga por uso 

EFS infrecuent ACCess EFS-IA 
hasta 92 de ahporro comparado con el EFS standar

EFS movrera automatixamente tus archivos (esto con una politica de EFS IA)



----------
Amazon fsx 
(es un efs en un servodor windows server)

efs para windows scope (az)

Amazon fsx lustre scope (region)


----------
elastic load balancer
across multiple az
4 ipos

aplication load balancer (http/hppts/gRPC) layer 7
network load balancer (tcp/udp) layer 4
gateway (GENEVE ip pakets) layer 3

----------
scaling group
scale out agrega más EC2 nistances
scale in remueve ex2 instances
replace inhealthy instances
across multiple az
----------
scaling group estrategias
* manual

* simple / step scaling
   when cloudwatch alarm is tirggered (example cpu > 70%), then add 2 unit
   when cloudwatch alarm is tirggered (example cpu < 70%), then remove 1
* target tracking scaling
   example i want the average asg cpu to staty at arround 40%
* Schedueled scalong
   anticipades based on konw usage patterns
* Predicted scaling
   use machine learning to prefcit future traffic ahead f time

--------------
S3
buckets are directories
bucket needs a name unique globally (across all regions)
bucjets scope are regions
key = the rest of the path
key = pefix + object name
max size = 5TB
if upload more than 5gb must use multipart upload

s3 replication (only if version exists)
* cros regios replication
* same regios replication
proper IAM permision to s3


S3 Storage Class
* S3 standar low user for frequently accessed data (availability 99.99) (durability 99.999999999) 
* s3 infrecuent access but require rapid access when needed (availability 99.9)
* S3 one zone-infrecuent access in a single AZ (durability 99.5)
* s3 Glacier low cost storage 
* s3 glacier instant retrieval 
* s3 glacier flexible retrieval (1,5 expedited, standar 3,5hours bulk, 5,12 hours)
* s3 glacier deep archive standar (12 hours) bulk (48 horus)
* s3 inteligent tiering 
   
S3 encryption
server side
client side

IAM access analyzer for s3 (bitácora)
---------
Snow ball (investigar que diabos es)
higly secure portable device to collect and proceess data at the edge
---------
AWS storage gateway (investigar)
file gateway
volume gateway
tape gateway

---------
RDS & Aurora

RDS (free tier)
Aurora (no free tier) (5x mysql) (3x postgresql)

RDS has multi region depoyment and multi az deployment
---------
Amazon ElastiCache

redis etc example
---------
Dynamo db

multi az depoyment
---------
Dynamo db acelerator
in-memory cache

dax only used to dynamo
---------
Dynamo db global table

---------
Redshift
onlile analytical procesing (analytics and data warehousing)
load data once every hour not every second
10x better performance than other data warehouse
column storage of datta

---------
AMAZON EMR

stand fro elastic map reduce

crate Hdoop cluster (big data)
use cases: data procesing, machine learing, web indexing, big data
---------
AMAZON athena

serverless query ervice to perform analytics against s3 objects
uses sql language to query files
suports CSV, JSON, ORC, Avro and Parquet (build on presto)

princing $5 per TB of data scanned
---------
AMAZON quicksight
serverless machine learning powered bussiness ingelligence server to create interactive dashboards

princing per session

---------
DocumentDB = mongodb

---------
Amazon neptune
graph database

---------
Amazon timestream 

fullt managed fast scalable serverless time series database

---------
amazon managed blockchain

join blockchain network

---------
Amazon glue = ETL

---------
Amazon DMS

database migration service


---------
ECR => Elastic container repository
---------
ECS => elastic container service
run docker containers

Fargate => Serverless offering


---------
EKS = elastic kubernetes service
cloud-agnostci

---------
serverless
just deploy code 
just depoy functions
ex: s3, dynamo, Fargate, lambda

---------
Lambda
* event driven
* cron job

pay per calls
   * first  1,000,000 calls are free
pay per duration
   * 400,000 BG-seconds
   * 


---------
api gateway
* proxy request
* suport restful apis
* support Security, user auth, api throttiling api keys, monitoring
---------
aws batch
are defined as docker images and run on ECS
same as lambda but you can set it on docker images 
and the file system can be EFS or EBS
also doest not have limit of time like lambda

---------
aws Lightsail
virtual servers storage database and networking
use templates
has high availability but no auto-scaling limited aws integrations
---------
Cloudformation
a declaravive way of outlining your aws infraestructure
infraestructure as code

to save costs
you can automate deletetion of template from 8 to 5 
(ingraestructure composer) (graph on aws)
---------
CDK
define your cloud infraestructure 
this "compile" to cloud formations template (json/yml)
great for lambda / great for docker container in ECS / EKS

---------
Beanstalk
is a developer centric view of deploying an app in aws
Beanstalk = platform as a service

single instance deploymnet (good for dev)
LB + ASG: great for production or pre-production web applications
asg only great for non-web apps in prod (workers etc)

---------
aws CodeDepoy (search for)

allow to deploy smotly version of an app

---------
aws CodeCommit deprecation :(

---------
aws codebuild (github actions) (search for)
only pay for the build time

---------
aws codepipeline (github actions) (search for)

---------
aws codeartifact (search for)
save code dependencies
(gradle, npm yarn )

---------
aws system manager (ssm)
helps ,manage your ec2 and on-primes system at scale
hybrid aws service